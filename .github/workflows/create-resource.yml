name: Create Resources

on:
  push:
    paths:
      - 'resource.json'
  workflow_dispatch:

jobs:
  create-resources:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Install and Upgrade Python Packages
      run: |
        sudo apt-get install -y python3-pip
        pip3 install --upgrade "urllib3<2" "chardet<4" requests

    - name: Install Databricks CLI
      run: |
        pip3 install databricks-cli

    - name: Parse JSON file and save environment variables
      id: parse_json
      run: |
        python3 <<EOF
        import json

        with open('resource.json') as f:
            data = json.load(f)

        outputs = {
            'platform_type': data['PlatformType'],
            'num_resources': len(data['Resources']),
            'resources': data['Resources']
        }

        with open('outputs.json', 'w') as f:
            json.dump(outputs, f)
        EOF
      continue-on-error: false

    - name: Load parsed environment variables
      id: load_outputs
      run: |
        cat outputs.json
        platform_type=$(python3 -c "import json; print(json.load(open('outputs.json'))['platform_type'])")
        num_resources=$(python3 -c "import json; print(json.load(open('outputs.json'))['num_resources'])")
        
        echo "::set-output name=platform_type::$platform_type"
        echo "::set-output name=num_resources::$num_resources"
        
        echo "Platform type is $platform_type"
        echo "Number of resources is $num_resources"
      continue-on-error: false
      
    - name: Load individual resources
      run: |
        resources=$(python3 -c "import json; data=json.load(open('outputs.json'))['resources']; print(data)")

        echo "${resources}" | jq -c '.[]' | while read resource; do
          echo "resource_type=$(echo "${resource}" | jq -r '.ResourceType')" >> $GITHUB_ENV
          echo "resource_name=$(echo "${resource}" | jq -r '.ResourceName')" >> $GITHUB_ENV
          echo "resource_config=$(echo "${resource}" | jq -r '.')" >> $GITHUB_ENV
        done

    - name: Configure Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        terraform_version: 1.0.11

    - name: Create AWS Resources
      if: steps.load_outputs.outputs.platform_type == 'AWS'
      run: |
        num_resources=${{ steps.load_outputs.outputs.num_resources }}
        rm -f main.tf   # Ensure main.tf is clean before starting

        for ((i=0; i<$num_resources; i++)); do
          resource_type=$(eval echo "\${resource_type}")
          resource_name=$(eval echo "\${resource_name}")
          resource_config=$(eval echo "\${resource_config}")

          echo "Creating $resource_type named $resource_name"

          case $resource_type in
            S3)
              echo "resource \"aws_s3_bucket\" \"$resource_name\" {
                bucket = \"$resource_name\"
              }" >> main.tf
              ;;
            EC2)
              ami=$(echo $resource_config | jq -r '.Ami')
              instance_type=$(echo $resource_config | jq -r '.InstanceType')
              echo "resource \"aws_instance\" \"$resource_name\" {
                ami           = \"$ami\"
                instance_type = \"$instance_type\"
              }" >> main.tf
              ;;
            SNS)
              echo "resource \"aws_sns_topic\" \"$resource_name\" {
                name = \"$resource_name\"
              }" >> main.tf
              ;;
            *)
              echo "Unsupported resource type: $resource_type"
              exit 1
              ;;
          esac
        done

        terraform init
        terraform apply -auto-approve

    - name: Process Databricks
      if: steps.load_outputs.outputs.platform_type == 'DATABRICK'
      run: |
        num_resources=${{ steps.load_outputs.outputs.num_resources }}

        for ((i=0; i<$num_resources; i++)); do
          resource_type=$(eval echo "\${resource_type}")
          resource_name=$(eval echo "\${resource_name}")
          resource_config=$(eval echo "\${resource_config}")

          echo "Creating Databricks resource: Type=$resource_type, Name=$resource_name"

          case $resource_type in
            CLUSTER)
              cluster_config=$(echo $resource_config | jq -r '.ClusterConfig')
              echo "Setting up Databricks Cluster ${resource_name} with config ${cluster_config}"
              databricks clusters create --json "$cluster_config"
              ;;
            JOB)
              job_config=$(echo $resource_config | jq -r '.JobConfig')
              echo "Setting up Databricks Job ${resource_name} with config ${job_config}"
              databricks jobs create --json "$job_config"
              ;;
            *)
              echo "Unsupported Databricks resource type: $resource_type"
              exit 1
              ;;
          esac
        done

    - name: Process Snowflake
      if: steps.load_outputs.outputs.platform_type == 'DATAFLAKE'
      run: |
        echo "Processing Snowflake resources..."
        num_resources=${{ steps.load_outputs.outputs.num_resources }}

        for ((i=0; i<$num_resources; i++)); do
          resource_type=$(eval echo "\${resource_type}")
          resource_name=$(eval echo "\${resource_name}")
          resource_config=$(eval echo "\${resource_config}")

          echo "Creating Snowflake resource: Type=$resource_type, Name=$resource_name"

          # Add your Snowflake related commands here based on the resource_type and resource_config
          
        done
